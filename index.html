<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yujun Shi</title>
  
  <meta name="author" content="Yujun Shi">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>
<!--
<div style="position: relative; right: 370px; text-align:right;">
  <small><em><q>It's about a man who has nothing, who risks everything, to feel something.</q> --Jessica Day</em></small>
</div>
-->

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>施宇钧 (Yujun Shi)</name>
              </p>
              <p>
                Greetings! My name is Yujun Shi.
                I'm currently a PhD student in ECE, National University of Singapore,
                advised by <a href="https://vyftan.github.io/index.html">Assoc Prof. Vincent Y. F. Tan</a>
                and <a href="https://sites.google.com/site/jshfeng/home">Dr. Jiashi Feng</a>.
                Previously, I received my B. Eng in Computer Science in Nankai University, advised by <a href="https://mmcheng.net/cmm/">Prof. Mingming Cheng</a>.
              </p>
              <p>
                I work on Machine Learning/Computer Vision in general.
                Currently, I'm especially interested in Federated/Continual Learning.
                I am open to discussion or collaboration. Feel free to drop me an email if you're interested.
              </p>
              <p style="text-align:center">
                <a href="mailto:shi.yujun@u.nus.edu">Email</a> &nbsp/&nbsp
                <a href="data/resume.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Okeolr8AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/Yujun-Shi">Github</a>
              </p>
              <small><em><q>It's about a man who has nothing, who risks everything, to feel something.</q> --Jessica Day</em></small>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <a href="images/img2.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/img2.jpg" class="hoverZoomLink"></a>
              <!--
              <p>
                Photo credit to <a href="http://jeff95.me/">Jianfeng Zhang</a>.
              </p>
              -->
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tbody><tr>
            <td width="100%" valign="middle">
              <heading>Publications</heading>
            </td>
          </tr>
          </tbody>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <papertitle>Towards Understanding and Mitigating Dimensional Collapse in Heterogeneous Federated Learning</papertitle>
            <br>
            <strong>Yujun Shi</strong>,
            Song Bai,
            Jian Liang,
            Wenqing Zhang,
            Vincent Y. F. Tan
            <br>
            <em>ICLR</em>, 2023
            <br>
            [<a href="https://arxiv.org/abs/2210.00226">arXiv link</a>]
            [<a href="https://github.com/Yujun-Shi/FedCLS">code</a>]
            <p></p>
            <p>
              We find dimensional collapse of representations is one of the culprit behind the performance degradation
              in heterogeneous Federated Learning. We propose FedDecorr to mitigate such problem and thus
              facilitating FL under data heterogeneity.
            </p>
          </td>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <papertitle>Mimicking the Oracle: An Initial Phase Decorrelation Approach for Class Incremental Learning</papertitle>
            <br>
            <strong>Yujun Shi</strong>,
            Kuangqi Zhou,
            Jian Liang,
            Zihang Jiang,
            Jiashi Feng,
            Philip Torr,
            Song Bai,
            Vincent Y. F. Tan
            <br>
            <em>CVPR</em>, 2022
            <br>
            [<a href="https://arxiv.org/abs/2112.04731">arXiv link</a>]
            [<a href="https://github.com/Yujun-Shi/CwD">code</a>]
            [<a href="data/cwd.bib">bibtex</a>]
            [<a href="data/cwd_poster.pdf">poster</a>]
            [<a href="https://www.bilibili.com/video/BV1s94y1277S?spm_id_from=444.41.list.card_archive.click&vd_source=fa65719b2d4e7994ab64a631336a3a99">video</a>]
            <p></p>
            <p>
              We propose a Class-wise Decorrelation regularizer that enables CIL learner at initial phase to mimic representations
              produced by the oracle model (the model jointly trained on all classes) and thus boosting Class Incremental Learning.
            </p>
          </td>
        </table>
        <!--
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tbody><tr>
            <td width="100%" valign="middle">
              <heading>Co-author Papers</heading>
            </td>
          </tr>
          </tbody>
        </tbody></table>
        -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <papertitle>All Tokens Matter: Token Labeling for Training Better Vision Transformers</papertitle>
            <br>
            Zihang Jiang,
            Qibin Hou,
            Li Yuan,
            Daquan Zhou,
            <strong>Yujun Shi</strong>,
            Xiaojie Jin,
            Anran Wang,
            Jiashi Feng
            <br>
            <em>NeurIPS</em>, 2021
            <br>
            [<a href="https://arxiv.org/abs/2104.10858">arXiv link</a>]
            [<a href="https://github.com/zihangJiang/TokenLabeling">code</a>]
            <p>
              Instead of only supervising the classification token in ViT,
              we propose a novel offline knowledge distillation method that supervises all output tokens
              and significantly boost ViT performance.
            </p>
          </td>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <papertitle>Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet</papertitle>
            <br>
            Li Yuan,
            Yunpeng Chen,
            Tao Wang,
            Weihao Yu,
            <strong>Yujun Shi</strong>,
            Zihang Jiang,
            Francis E. H. Tay,
            Jiashi Feng,
            Shuicheng Yan
            <br>
            <em>ICCV</em>, 2021
            <br>
            [<a href="https://arxiv.org/abs/2101.11986">arXiv link</a>]
            [<a href="https://github.com/yitu-opensource/T2T-ViT">code</a>]
            <p>
              By injecting the missing local information into vanilla ViT with our proposed T2T module,
              we achieve decent ImageNet classification accuracy when training ViT from scratch.
            </p>
          </td>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <papertitle>Continual Learning via Bit-Level Information Preserving</papertitle>
            <br>
            <strong>Yujun Shi</strong>,
            Li Yuan,
            Yunpeng Chen,
            Jiashi Feng
            <br>
            <em>CVPR</em>, 2021
            <br>
            [<a href="https://arxiv.org/abs/2105.04444">arXiv link</a>]
            [<a href="https://github.com/Yujun-Shi/BLIP">code</a>]
            [<a href="data/blip.bib">bibtex</a>]
            [<a href="https://www.youtube.com/watch?v=VJTiJIWP6P0&t=641s">talk @ ContinualAI</a>]
            <p></p>
            <p>
              By viewing learning algorithm as a channel (input data and output model parameters)
              and using chain rule of mutual information,
              we propose a novel algorithm called Bit-Level Information Preserving (BLIP) to combat forgetting.
            </p>
          </td>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <papertitle>Leveraging Instance-, Image- and Dataset-Level
              Information for Weakly Supervised Instance
              Segmentation</papertitle>
            <br>
            Yun Liu,
            Yu-huan Wu,
            Peisong Wen,
            <strong>Yujun Shi</strong>,
            Yu Qiu,
            Ming-Ming Cheng
            <br>
            <em>TPAMI</em>
            <br>
            [<a href="http://mmcheng.net/mftp/Papers/21PAMI_InsImgDatasetWSIS.pdf">paper link</a>]
            [<a href="https://github.com/yun-liu/LIID">code</a>]
            <p>
              By leveraging multi-level information,
              we achieve SOTA results on weakly-supervised instance/semantic segmentation.
            </p>
          </td>
        </table>

        <table table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tbody><tr>
            <td width="100%" valign="middle">
              <heading>Education</heading>
            </td>
          </tr>
          </tbody>
        </tbody></table>

        <table table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tbody>
              <td width="15%">
                <img src="images/nus.png" width="80">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <strong>National University of Singapore</strong>, Singapore <br>
                <br>
                PhD in Machine Learning (Jan. 2021 to present)<br>
              </td>
            </tr> 
        <table table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tbody>
              <td width="15%">
                <img src="images/Nankai.png" width="80">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <strong>Nankai University</strong>, Tianjin, China <br>
                <br>
                B. Eng in Computer Science (2015 to 2019)
                <br>
                GPA: 92.14/100, Rank: 1/93
              </td>
            </tr>
        <table table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tbody>
              <td width="15%">
                <img src="images/cfms.jpeg" width="80">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <strong>Changsha First Middle School</strong>, Changsha, China <br>
                <br>
                High School (2012 to 2015)
              </td>
            </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Relevant Courses</heading>
            <br>
            EE6139 Information Theory and its Applications
            <br>
            EE5137 Stochastic Process
            <br>
            IE6520 Theory and Algorithms for Online Learning
            <br>
          </td>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Tutoring & TA</heading>
            <br>
            EE2211 Introduction to Machine Learning (Fall 2022)
            <br>
            EE2012A Analytical Methods in Electrical and Computer Engineering (Spring 2022)
            <br>
          </td>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Awards</heading>
            <br>
            <em>NUS Research Scholarship (Jan 2022 - Jan 2025)</em>
            <br>
            <em>National Scholarship Award, PRC (2016)</em>
            <br>
            <em>Nankai First Class Scholarship (2017, 2018)</em>
            <br>
          </td>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Academic Service (Reviewer)</heading>
            <br>
            <em>CVPR 2023, ICCV 2023, CoLLAs 2023</em>
            <br>
            <em>TNNLS (2022), CoLLAs 2022</em>
            <br>
          </td>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Invited Talk</heading>
            <br>
            <span style="color: #ff0000">I'm always more than willing to give a talk about my works and my field of study!</span>
            <span style="color: #ff0000">Feel free to reach out :)</span>
            <br><br>
            <strong>Introduction to Federated Learning</strong> @ UMass Amherst, host: Hong Yu
            <br>
            <strong>Continual Learning via Bit-Level Information Preserving</strong> @ ContinualAI, host: Vincenzo Lomonaco
            <br>
          </td>
        </table>

        <table width="100%" cellspacing="0" cellpadding="20" border="0" align="center">
          <tbody><tr>
            <td>
            <br>
            <p align="right">
              <font size="2">
                <a href="https://jonbarron.info/">template from here</a>
              </font>
            </p>
            </td>
          </tr>
          </tbody>
        </table>        
      </td>
    </tr>
  </table>
</body>

</html>
